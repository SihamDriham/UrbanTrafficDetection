services:
  # ==================== HADOOP NAMENODE ====================
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: unless-stopped
    ports:
      - "9870:9870"
      - "9000:9000"
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
      - ./data:/data
    environment:
      - CLUSTER_NAME=bigdata-cluster
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - CORE_CONF_hadoop_http_staticuser_user=root
      - CORE_CONF_hadoop_proxyuser_hue_hosts=*
      - CORE_CONF_hadoop_proxyuser_hue_groups=*
      - HDFS_CONF_dfs_webhdfs_enabled=true
      - HDFS_CONF_dfs_permissions_enabled=false
      - HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false
    networks:
      - bigdata

  # ==================== HADOOP DATANODE ====================
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: unless-stopped
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - CORE_CONF_hadoop_http_staticuser_user=root
      - CORE_CONF_hadoop_proxyuser_hue_hosts=*
      - CORE_CONF_hadoop_proxyuser_hue_groups=*
      - HDFS_CONF_dfs_webhdfs_enabled=true
      - HDFS_CONF_dfs_permissions_enabled=false
    depends_on:
      - namenode
    networks:
      - bigdata

  # ==================== YARN RESOURCEMANAGER ====================
  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    restart: unless-stopped
    ports:
      - "8088:8088"
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
      - YARN_CONF_yarn_resourcemanager_address=resourcemanager:8032
      - YARN_CONF_yarn_resourcemanager_scheduler_address=resourcemanager:8030
      - YARN_CONF_yarn_resourcemanager_resource__tracker_address=resourcemanager:8031
      - YARN_CONF_yarn_log_aggregation_enable=true
      - YARN_CONF_yarn_nodemanager_remote___app___log___dir=/app-logs
    depends_on:
      - namenode
      - datanode
    networks:
      - bigdata

  # ==================== YARN NODEMANAGER ====================
  nodemanager:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    restart: unless-stopped
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
      - YARN_CONF_yarn_nodemanager_aux___services=mapreduce_shuffle
      - YARN_CONF_yarn_nodemanager_resource_memory___mb=4096
      - YARN_CONF_yarn_nodemanager_resource_cpu___vcores=2
      - YARN_CONF_yarn_log_aggregation_enable=true
    depends_on:
      - resourcemanager
    networks:
      - bigdata

  # ==================== HIVE METASTORE DATABASE ====================
  hive-metastore-postgresql:
    image: postgres:11
    container_name: hive-metastore-postgresql
    restart: unless-stopped
    environment:
      POSTGRES_DB: metastore
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive
    volumes:
      - hive_metastore:/var/lib/postgresql/data
    networks:
      - bigdata

  # ==================== HIVE METASTORE ====================
  hive-metastore:
    image: apache/hive:3.1.3
    container_name: hive-metastore
    restart: unless-stopped
    ports:
      - "9083:9083"
    environment:
      SERVICE_NAME: metastore
      DB_TYPE: postgres
      SKIP_SCHEMA_INIT: "true"
      DB_DRIVER: postgres
      SERVICE_OPTS: "-Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver 
                     -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://hive-metastore-postgresql:5432/metastore 
                     -Djavax.jdo.option.ConnectionUserName=hive 
                     -Djavax.jdo.option.ConnectionPassword=hive"
    depends_on:
      - hive-metastore-postgresql
      - namenode
    command: >
      /opt/hive/bin/hive --service metastore
    networks:
      - bigdata

  # ==================== APACHE SPARK MASTER ====================
  spark-master:
    image: apache/spark:3.5.0
    container_name: spark-master
    restart: unless-stopped
    ports:
      - "8080:8080"
      - "7077:7077"
      - "4040:4040"
    environment:
      - SPARK_NO_DAEMONIZE=true
    volumes:
      - ./notebooks:/notebooks
      - ./data:/data
      - ./spark-apps:/spark-apps
      - ./conf/hive-site.xml:/opt/spark/conf/hive-site.xml
    networks:
      - bigdata
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --host spark-master --port 7077 --webui-port 8080

  # ==================== APACHE SPARK WORKER ====================
  spark-worker:
    image: apache/spark:3.5.0
    container_name: spark-worker
    restart: unless-stopped
    environment:
      - SPARK_NO_DAEMONIZE=true
      - SPARK_WORKER_MEMORY=4G
      - SPARK_WORKER_CORES=2
    depends_on:
      - spark-master
    volumes:
      - ./data:/data
      - ./spark-apps:/spark-apps
      - ./conf/hive-site.xml:/opt/spark/conf/hive-site.xml
    networks:
      - bigdata
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

  # ==================== APACHE ZEPPELIN ====================
  zeppelin:
    build: ./zeppelin
    container_name: zeppelin
    ports:
      - "8090:8080"
    environment:
      - SPARK_HOME=/opt/spark
      - SPARK_MASTER=spark://spark-master:7077
    volumes:
      - ./notebooks:/notebook
      - ./data:/data
      - ./conf/hive-site.xml:/opt/spark/conf/hive-site.xml
    depends_on:
      - spark-master
    networks:
      - bigdata

networks:
  bigdata:
    driver: bridge

volumes:
  hadoop_namenode:
  hadoop_datanode:
  hive_metastore:
  zeppelin_logs:
  zeppelin_conf: