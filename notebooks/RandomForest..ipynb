{
  "metadata": {
    "name": "RandomForest",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Importation des bibliothèques\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, mean, variance\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.regression import RandomForestRegressor\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n\n%pyspark\n# Création de la SparkSession\nspark \u003d SparkSession.builder \\\n    .appName(\"RandomForest\") \\\n    .master(\"spark://spark-master:7077\") \\\n    .config(\"spark.sql.warehouse.dir\", \"hdfs://namenode:9000/user/hive/warehouse\") \\\n    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\") \\\n    .enableHiveSupport() \\\n    .getOrCreate()\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Lecture du fichier parquet depuis HDFS\ntraffic_df \u003d spark.read.parquet(\"hdfs://namenode:9000/traffic_volume_cleaned_encoded.parquet\")"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n\n%pyspark\n\nlabel_col \u003d \"traffic_volume\"\nfeature_cols \u003d [col for col in traffic_df.columns if col !\u003d label_col]\n\n# Création de la colonne features\nassembler \u003d VectorAssembler(inputCols\u003dfeature_cols, outputCol\u003d\"features\")\ndata \u003d assembler.transform(traffic_df).select(\"features\", col(label_col).alias(\"label\"))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%pyspark\n# Séparation du dataset en ensembles d’entraînement et de test\ntrain_df, test_df \u003d data.randomSplit([0.75, 0.25], seed\u003d0)"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n\n%pyspark\n# Entraînement du Random Forest et prédiction sur le jeu de test\nrf \u003d RandomForestRegressor(featuresCol\u003d\"features\", labelCol\u003d\"label\", numTrees\u003d100, maxDepth\u003d5, maxBins\u003d50)\nrf_model \u003d rf.fit(train_df)\n\n# Prédiction\npredictions \u003d rf_model.transform(test_df)\npredictions.select(\"label\", \"prediction\").show(5)\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n\n%pyspark\n# Évaluation des performances du modèle \nevaluator \u003d RegressionEvaluator(labelCol\u003d\"label\", predictionCol\u003d\"prediction\")\n\nr2 \u003d evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\nmae \u003d evaluator.evaluate(predictions, {evaluator.metricName: \"mae\"})\nmse \u003d evaluator.evaluate(predictions, {evaluator.metricName: \"mse\"})\nrmse \u003d evaluator.evaluate(predictions, {evaluator.metricName: \"rmse\"})\n\nprint(f\"R Squared : {r2}\")\nprint(f\"Mean Absolute Error : {mae}\")\nprint(f\"Mean Squared Error : {mse}\")\nprint(f\"Root Mean Squared Error : {rmse}\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n\n%pyspark\n# Recherche des meilleurs hyperparamètres avec Cross-Validation\nparamGrid \u003d ParamGridBuilder() \\\n    .addGrid(rf.maxDepth, [3, 5, 7, 9]) \\\n    .addGrid(rf.numTrees, [5, 10, 15]) \\\n    .build()\n\ncv \u003d CrossValidator(estimator\u003drf,\n                    estimatorParamMaps\u003dparamGrid,\n                    evaluator\u003devaluator,\n                    numFolds\u003d3)\n\ncv_model \u003d cv.fit(train_df)\nbest_model \u003d cv_model.bestModel\n\nprint(\"Meilleurs paramètres :\")\nprint(f\"Max Depth : {best_model.getMaxDepth()}\")\nprint(f\"Num Trees : {best_model.getNumTrees}\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n\n%pyspark\n# Évaluation biais et variance du modèle\n# Moyennes\nmean_actual \u003d test_df.select(mean(\"label\")).collect()[0][0]\nmean_pred \u003d predictions.select(mean(\"prediction\")).collect()[0][0]\n\n# Variances\nvar_actual \u003d test_df.select(variance(\"label\")).collect()[0][0]\nvar_pred \u003d predictions.select(variance(\"prediction\")).collect()[0][0]\n\nprint(\"Bias Error\")\nprint(f\"Actual value : {mean_actual}\")\nprint(f\"Predicted value : {mean_pred}\")\n\nprint(\"Variance Error\")\nprint(f\"Actual value : {var_actual}\")\nprint(f\"Predicted value : {var_pred}\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%pyspark\n# Création de la base Hive et enregistrement des métriques du modèle\nspark.sql(\"CREATE DATABASE IF NOT EXISTS traffic_ml\")\nspark.sql(\"USE traffic_ml\")\nspark.sql(\"CREATE TABLE IF NOT EXISTS model_metrics (model_name STRING, rmse DOUBLE, r2 DOUBLE, mae DOUBLE)\")\n\nspark.sql(f\"\"\"\n    INSERT INTO model_metrics VALUES (\n        \u0027RandomForest\u0027,\n        {rmse},\n        {r2},\n        {mae}\n    )\n\"\"\")"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Affichage des métriques des modèles enregistrées\nspark.sql(\"SELECT * FROM traffic_ml.model_metrics\").show()"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}